# XTTS Streaming TTS WebSocket (совместим с ElevenLabs "stream-input")

Этот сервис — тонкая обёртка над вашей моделью TTS (XTTS), которая предоставляет потоковый WebSocket API, **совместимый с протоколом ElevenLabs `stream-input`**. Поверх генератора добавлены:

* инициализационный handshake `ttsInitRequest`;
* валидация формата аудио `EL_AUDIO_FORMAT` вида `pcm_<sr>`;
* сглаживание выдачи через **пейсинг** (целевой лид-буфер ≈ 20 мс);
* пакетизация аудио: расписание по символам (триггер генерации) и по «кадрам» (склейка кадров в один WS-пакет);
* **жёсткая нарезка** любого исходящего PCM на кусочки ≤ **60 мс** ("time‑shard") для ранней доставки и стабильного буфера;
* два режима работы: `generate` (генерация на лету) и `forward` (ретрансляция из Redis);
* ограничение параллелизма через семафор GPU (не плодит копии модели в VRAM);
* прогрев модели при старте (уменьшает TTFT «первого запроса»).

> Док ниже описывает поведение **после всех внесённых изменений** (stream_chunk_size по умолчанию 10, прогрев, time‑shard ≤ 60 мс и т.д.).

---

## TL;DR — как запустить и проверить

1. Установите зависимости проекта.
2. Подготовьте `config.yaml` (пути к весам, референс-голосу и т.п.).
3. Запустите сервер:

(Из корневой директории)

```bash
XTTS_SETTINGS_FILE=/путь/до/вашего/config.yaml PYTHONPATH=src python -m xtts_stream.service.app
```

4. Прогоните клиент (пример):

```bash
python example.py \
  --host 127.0.0.1 --port 60215 --voice-id VOICE123 \
  --sr 24000 --text "Привет, это тест." --play --no-save \
  --stream_chunk_size 3 --left_context_seconds 0.6
```

Ожидаемо: TTFA ≈ 170–250 мс после прогрева, много небольших WS‑пакетов, ровное воспроизведение.

---

## Архитектура на 10 000 м над уровнем моря

```
Клиент ─WS─> [FastAPI/WS] ──┐
                           │   Генерация (mode=generate)
                           ├─> [Wrapper → XTTS.inference_stream] → PCM
                           │
                           │   Форвардинг (mode=forward)
                           └─> [Redis pubsub audio_channel] → PCM

PCM → Time‑Shard (≤60 мс) → Pacer(≈20 мс lead) → Base64(JSON) → WS → Клиент
```

---

## Конфигурация модели

Сервис ожидает `config.yaml` (пути и настройки), который читает `load_settings`. Ключевые поля:

```yaml
service:
  host: 0.0.0.0
  port: 60215
  max_concurrency: 2   # глобальный лимит одновременных генераций

model:
  config_path: path/to/config.json
  checkpoint_path: path/to/model.pth
  tokenizer_path: path/to/tokenizer.json
  speaker_wav: path/to/ref.wav
  language: ru
  device: auto   # 'cuda'|'cpu'|'auto'
```

> Лимит `max_concurrency` — это **одновременные генерации**, а не число копий модели. Весы в VRAM однажды загружены; параллелизм увеличивает только рабочие буферы/кэш.

Переменные окружения (fallback):

* `XTTS_SETTINGS_FILE` — путь к `config.yaml` (по умолчанию `./config.yaml`).
* `REDIS_URL` — URL Redis для режима `forward` (`redis://localhost:6379/0`).

---

## Запуск

(Из корневой директории)

```bash
XTTS_SETTINGS_FILE=/путь/до/вашего/config.yaml PYTHONPATH=src python -m xtts_stream.service.app
```

При старте:

* загружается модель XTTS;
* выполняется короткий **прогрев** (генерация первого кадра);
* сервер готов к приёму WS‑соединений.

---

## Протокол WebSocket (совместим с ElevenLabs `stream-input`)

### Эндпоинт

```
GET ws://<host>:<port>/v1/text-to-speech/{voice_id}/stream-input
```

### Query‑параметры (fallback до `ttsInitRequest`)

| Параметр               |   Тип | По умолчанию | Описание                                                                     |
| ---------------------- | ----: | -----------: | ---------------------------------------------------------------------------- |
| `output_format`        |   str |  `pcm_24000` | **Жёсткий** параметр формата. Поддержка: `pcm_16000/22050/24000/44100/48000` |
| `mode`                 |   str |   `generate` | `generate` или `forward` (в `forward` необходим `audio_channel` из init)     |
| `stream_chunk_size`    |   int |       **10** | Размер «фрейма» генерации модели (кол-во токенов/шаг)                        |
| `overlap_wav_len`      |   int |          512 | Оверлэп для кросс‑фейда в аудио                                              |
| `left_context_seconds` | float |          1.0 | Левый контекст для декодера (сек), включает «обрезку истории»                |
| `speed`                | float |          1.0 | Скорость речи (масштаб по времени)                                           |
| `language`             |   str |            — | Языковой хинт для модели                                                     |
| `sync_alignment`       |  bool |        false | Возвращать упрощённое выравнивание                                           |
| `inactivity_timeout`   | float |           20 | Таймаут неактивности соединения (сек)                                        |

> После получения `ttsInitRequest` значения из init **переопределяют** query и **фиксируются** (для «жёстких» параметров).

### Инициализация: `ttsInitRequest`

Первое сообщение от клиента **желательно** присылать как `ttsInitRequest`:

```json
{
  "type": "ttsInitRequest",
  "audio_format": "pcm_24000",                    
  "generation_config": {
    "chunk_length_schedule": [32, 64],             
    "chunk_length_schedule_frames": [1],           
    "speed": 1.0,
    "language": "ru"
  },
  "target_lead_ms": 20,                           
  "audio_channel": "sess:123:audio"              
}
```

* `audio_format` / `EL_AUDIO_FORMAT`: **жёстко фиксирует** sample rate. Менять после старта сессии нельзя.
* `target_lead_ms`: целевой лид-буфер, фиксируется при создании пейсера.
* Расписания (опционально):

  * `chunk_length_schedule` — **когда триггерить генерацию** (по длине входного буфера текста в символах);
  * `chunk_length_schedule_frames` — **как паковать кадры** в один WS‑пакет; по умолчанию используется `1` (каждый кадр сразу).
* Для `mode=forward` требуется `audio_channel` — имя Redis‑канала, из которого будет читаться звук.

Если `ttsInitRequest` не пришёл в течение ~1.5 с — сервер продолжит работу по значениям из query.

### Сообщения генерации

* `{"text": "..."}` — добавить текст к буферу.
* `{"flush": true}` — принудительно начать генерацию накопленного текста.
* `{"text": ""}` (пустая строка) — **маркер конца батча**: дождаться завершения, выслать хвост и `isFinal`.
* В **любом** сообщении можно прислать `generation_config`, чтобы обновить динамические параметры (например, `speed`, `language`, расписания). Они применяются **со следующего батча**.

### Ответы сервера

Поток аудио (много таких сообщений):

```json
{
  "audio": "<base64 PCM16 mono>",
  "isFinal": false,
  "normalizedAlignment": {                   
    "charStartTimesMs": [0],
    "charDurationsMs": [60.0]
  }
}
```

Финал батча:

```json
{"isFinal": true}
```

Ошибки (пример валидации формата):

```json
{"error": "Invalid EL_AUDIO_FORMAT: ..."}
```

Соединение закрывается с кодом 1003/1008 при фатальных ошибках, 1000 — по таймауту/завершению.

---

## Режимы работы

### Generate (по умолчанию)

Текст → XTTS → аудиокадры (PCM float32) → PCM16 → **time‑shard ≤60 мс** → пейсинг → WS.

* `stream_chunk_size` (по умолчанию **10**) влияет на гранулярность «сырых» кадров от ядра; меньше — кадры чаще и короче.
* `left_context_seconds` включает «обрезку истории», что делает кадры стабильнее по длительности.
* Пакетизация «по кадрам» (`chunk_length_schedule_frames`) по умолчанию `1` — каждый кадр обрабатывается сразу. Дополнительно поверх применяется **time‑shard**, так что даже «крупный» кадр дробится ≤60 мс.

### Forward (Redis)

Вместо генерации читаем аудио из Redis Pub/Sub канала `audio_channel` (задаётся в init). Ожидается, что публикации содержат:

```json
{"audio": "<base64 PCM16>", "isFinal": false}
```

Мы **также режем** каждый входящий кусок на ≤60 мс и пейсингом отправляем по WS. При `isFinal: true` завершаем батч.

Настройки:

* `REDIS_URL` (env) — адрес Redis.
* Канал подписки — `audio_channel` из init.

---

## Пейсинг и нарезка (что и как работает)

### Пейсинг (Pacer)

* Вычисляет `bytes_per_sec = sr * 2 * channels` и `ms_per_byte`.
* Отслеживает, сколько «миллисекунд аудио» уже отправлено (`sent_ms`) и сколько прошло реального времени.
* Перед отправкой очередного **шарда** (кусочка) проверяет «на сколько мы опережаем» и при необходимости ждёт, чтобы придержать лид ≈ `target_lead_ms` (по умолчанию 20 ± 2 мс).

### Нарезка (Time‑Shard)

* Любой собранный PCM‑буфер нарезается по длительности на кусочки ≤ **60 мс** (настраивается константой `MAX_PACKET_MS`).
* Это уменьшает задержку доставки первого слышимого фрагмента и делает поток ровным. Пейсинг применяем **к каждому шард‑пакету**.

> Нарезка — это логистика доставки, она не ускоряет саму генерацию, но **сильно улучшает UX** и стабильность буфера.

---

## Параллелизм и жизненный цикл

* Глобальный семафор `gpu_sema = asyncio.Semaphore(MAX_CONCURRENCY)` ограничивает **одновременные генерации**.
* Модель загружается один раз при старте; прогрев делает первую реальную генерацию быстрой.
* Корректное закрытие модели в `lifespan`.

---

## Клиент `example.py` (коротко)

* Подключается к серверу, отправляет `ttsInitRequest`, стримит текст, делает `flush`, затем финальный `"text": ""`.
* Умеет **сохранять в WAV** и/или **проигрывать вживую через `ffplay`** (`--play`).
* По умолчанию **не** включает расписание «по кадрам». Для чистого стрима используйте маленький `--stream_chunk_size` и `--left_context_seconds`:

```bash
python example.py \
  --host 127.0.0.1 --port 60215 --voice-id VOICE123 \
  --sr 24000 --text "Длинный текст ..." \
  --stream_chunk_size 3 --left_context_seconds 0.6 \
  --play --no-save
```

Метрики, которые печатает клиент:

* **TTFT** — время до первой аудио‑посылки на уровне сети;
* **TTFA** — время от момента `flush` до первой аудио‑посылки;
* количество пакетов и суммарная длительность полученного аудио.

---

## Тюнинг производительности

* **Уменьшить `stream_chunk_size`** (3–5): чаще, короче «сырые» кадры → быстрее первый «фрагмент» и меньше сетевых накладных.
* **`left_context_seconds`** 0.5–1.0: стабильнее и предсказуемее длительность кадров.
* **`overlap_wav_len`** 512–1024 (кратно hop): гладкие стыки.
* **Прогрев** уже включён — снижает TTFT «первого запроса».
* **Сеть**: держите MTU/RTT под контролем; включённая нарезка ≤ 60 мс нивелирует большинство проблем.

---

## Совместимость с ElevenLabs

* Эндпоинт и формат сообщений (тип `ttsInitRequest`, `flush`, пустой `text` как конец батча, `isFinal`) совместимы с контрактом `stream-input`.
* `EL_AUDIO_FORMAT` поддерживается в виде `audio_format` и `EL_AUDIO_FORMAT`.
* Доп. поля (`target_lead_ms`, расписания по кадрам) — расширения и не ломают совместимость.
